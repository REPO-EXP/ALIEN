{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c240601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting ALIEN Test on cuda (Strict Numpy Noise Mode)\n",
      "üìÇ Output Dir: ./output_alien_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1262b53858354c9b9cdba42ee148d038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded Pretrained Watermark Models from ./ALIEN_Models\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/wm_bench/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/wm_bench/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /root/miniconda3/envs/wm_bench/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "\n",
      "üì¢ Processing 1 images...\n",
      "[1111/1] Generating: A cat, soft golden lighting, cinematic bokeh, high...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7dc3c9853a439eac555ed38c4dcbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b4e3ded1ac4ae8a06573a3cf6ff8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìä ALIEN WATERMARK REPORT (N=1)\n",
      "==================================================\n",
      "Visual Quality:\n",
      "  PSNR  : 27.96\n",
      "  SSIM  : 0.8562\n",
      "  LPIPS : 0.1192\n",
      "\n",
      "Robustness (Bit Accuracy):\n",
      "--------------------------------------------------\n",
      "Attack          | Accuracy  \n",
      "--------------------------------------------------\n",
      "CLEAN           | 1.0000\n",
      "NOISE           | 1.0000\n",
      "BLUR            | 1.0000\n",
      "JPEG            | 1.0000\n",
      "==================================================\n",
      "‚úÖ Results saved to: ./output_alien_test\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "from typing import Optional, List, Union, Dict, Any\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import lpips\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import sys\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "class WatermarkInjectionPipeline(StableDiffusionPipeline):\n",
    "    def __init__(self, vae, text_encoder, tokenizer, unet, scheduler, \n",
    "                 safety_checker=None, feature_extractor=None, image_encoder=None, \n",
    "                 requires_safety_checker=False, wm_encoder=None, wm_decoder=None):\n",
    "        super().__init__(vae, text_encoder, tokenizer, unet, scheduler, \n",
    "                         safety_checker, feature_extractor, image_encoder, requires_safety_checker)\n",
    "        self.wm_encoder = wm_encoder\n",
    "        self.wm_decoder = wm_decoder\n",
    "        self._inference_mode = True\n",
    "    \n",
    "    def set_inference_mode(self, mode=True):\n",
    "        self._inference_mode = mode\n",
    "        if self.unet: \n",
    "            self.unet.eval() if mode else self.unet.train()\n",
    "    \n",
    "    def _get_beta_t(self, t, scheduler):\n",
    "        if hasattr(scheduler, 'alphas_cumprod'):\n",
    "            alphas = scheduler.alphas_cumprod\n",
    "        elif hasattr(scheduler, 'alphas_cumprod_gpu'):\n",
    "             alphas = scheduler.alphas_cumprod_gpu\n",
    "        else:\n",
    "            return torch.tensor(1.0, device=self.device) \n",
    "\n",
    "        if torch.is_tensor(t): \n",
    "            t_idx = t.cpu().item()\n",
    "            alpha = alphas[t_idx]\n",
    "        else: \n",
    "            alpha = alphas[t]\n",
    "            \n",
    "        alpha = alpha.detach().clone() if torch.is_tensor(alpha) else torch.tensor(alpha, device=self.device)\n",
    "        return torch.sqrt(alpha) / torch.sqrt(1 - alpha)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self, \n",
    "        prompt: Union[str, List[str]], \n",
    "        latents: Optional[torch.FloatTensor] = None, \n",
    "        wm_injection_start_step: int = 20, \n",
    "        wm_injection_end_step: int = 45, \n",
    "        wm_weight: float = 1.0, \n",
    "        secret_input: Optional[torch.Tensor] = None, \n",
    "        height: Optional[int] = None, \n",
    "        width: Optional[int] = None, \n",
    "        num_inference_steps: int = 50, \n",
    "        guidance_scale: float = 7.5, \n",
    "        enable_watermark: bool = True, \n",
    "        **kwargs\n",
    "    ):\n",
    "        self.set_inference_mode(True)\n",
    "        \n",
    "        height = height or self.unet.config.sample_size * self.vae_scale_factor\n",
    "        width = width or self.unet.config.sample_size * self.vae_scale_factor\n",
    "        \n",
    "        if isinstance(prompt, str):\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = len(prompt)\n",
    "            \n",
    "        device = self._execution_device\n",
    "        \n",
    "        prompt_embeds, neg_embeds = self.encode_prompt(\n",
    "            prompt, device, 1, guidance_scale > 1.0, negative_prompt=None\n",
    "        )\n",
    "        text_embeddings = torch.cat([neg_embeds, prompt_embeds]) if guidance_scale > 1.0 else prompt_embeds\n",
    "        \n",
    "        self.scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "        \n",
    "        if latents is None:\n",
    "            latents = self.prepare_latents(\n",
    "                batch_size, self.unet.config.in_channels, height, width, \n",
    "                text_embeddings.dtype, device, kwargs.get('generator'), None\n",
    "            )\n",
    "        else:\n",
    "            latents = latents.to(device=device, dtype=text_embeddings.dtype)\n",
    "\n",
    "        wm_residual = None\n",
    "        if enable_watermark and self.wm_encoder is not None and secret_input is not None:\n",
    "            secret_input = secret_input.to(device=device, dtype=text_embeddings.dtype)\n",
    "            wm_residual = self.wm_encoder(secret_input)\n",
    "            \n",
    "            if wm_residual.shape[0] != latents.shape[0]:\n",
    "                wm_residual = wm_residual.repeat(latents.shape[0], 1, 1, 1)\n",
    "\n",
    "        extra_kwargs = self.prepare_extra_step_kwargs(kwargs.get('generator'), 0.0)\n",
    "        num_warmup_steps = len(self.scheduler.timesteps) - num_inference_steps * self.scheduler.order\n",
    "        \n",
    "        with self.progress_bar(total=num_inference_steps) as progress_bar:\n",
    "            for i, t in enumerate(self.scheduler.timesteps):\n",
    "                latent_model_input = torch.cat([latents] * 2) if guidance_scale > 1.0 else latents\n",
    "                latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
    "                \n",
    "                noise_pred = self.unet(\n",
    "                    latent_model_input, t, encoder_hidden_states=text_embeddings\n",
    "                ).sample\n",
    "                \n",
    "                if guidance_scale > 1.0:\n",
    "                    uncond, text = noise_pred.chunk(2)\n",
    "                    noise_pred = uncond + guidance_scale * (text - uncond)\n",
    "                \n",
    "                if wm_residual is not None and wm_injection_start_step <= i <= wm_injection_end_step:\n",
    "                    beta_t = self._get_beta_t(t, self.scheduler)\n",
    "                    noise_pred = noise_pred - beta_t * wm_weight * wm_residual\n",
    "                \n",
    "                latents = self.scheduler.step(noise_pred, t, latents, **extra_kwargs).prev_sample\n",
    "                \n",
    "                if i == len(self.scheduler.timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % self.scheduler.order == 0):\n",
    "                    progress_bar.update()\n",
    "            \n",
    "        if not kwargs.get(\"output_type\") == \"latent\":\n",
    "            image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n",
    "            current_bs = image.shape[0]\n",
    "            do_denormalize = [True] * current_bs\n",
    "            image = self.image_processor.postprocess(\n",
    "                image, output_type=\"pil\", do_denormalize=do_denormalize \n",
    "            )\n",
    "        else:\n",
    "            image = latents\n",
    "            \n",
    "        return {\"images\": image, \"latents\": latents}\n",
    "\n",
    "class DistortionUnit:\n",
    "    def __init__(self, device='cuda'):\n",
    "        self.device = device\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def apply_distortion(self, img, method, **kwargs):\n",
    "        if not isinstance(img, Image.Image):\n",
    "             img = self.to_pil(img.cpu()) if isinstance(img, torch.Tensor) else img\n",
    "        \n",
    "        if method == 'clean': \n",
    "            return img\n",
    "            \n",
    "        if method == 'gaussian_noise':\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            img_np = np.array(img, dtype=np.uint8)\n",
    "            \n",
    "            std = kwargs.get('std', 0.1)\n",
    "            \n",
    "            g_noise = np.random.randn(*img_np.shape).astype(np.float32) * (std * 255)\n",
    "            \n",
    "            noisy_array = np.clip(img_np.astype(np.float32) + g_noise, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            return Image.fromarray(noisy_array)\n",
    "\n",
    "        img_tensor = self.to_tensor(img).to(self.device)\n",
    "        \n",
    "        if method == 'gaussian_blur':\n",
    "            k = kwargs.get('kernel_size', (5, 5))\n",
    "            s = kwargs.get('sigma', (1.0, 1.0))\n",
    "            distorted = transforms.GaussianBlur(kernel_size=k, sigma=s)(img_tensor)\n",
    "            \n",
    "        elif method == 'jpeg_compression':\n",
    "            pil_temp = self.to_pil(img_tensor.cpu())\n",
    "            buffer = io.BytesIO()\n",
    "            quality = kwargs.get('quality', 50)\n",
    "            pil_temp.save(buffer, format=\"JPEG\", quality=quality)\n",
    "            buffer.seek(0)\n",
    "            return Image.open(buffer).convert('RGB')\n",
    "        \n",
    "        else:\n",
    "            distorted = img_tensor\n",
    "\n",
    "        distorted = torch.clamp(distorted, 0.0, 1.0)\n",
    "        return self.to_pil(distorted.cpu())\n",
    "\n",
    "class ImageQualityEvaluator:\n",
    "    def __init__(self, device='cuda'):\n",
    "        self.device = device\n",
    "        try: \n",
    "            self.lpips_model = lpips.LPIPS(net='alex').eval().to(device)\n",
    "        except: \n",
    "            self.lpips_model = None\n",
    "            \n",
    "    def _to_numpy(self, img):\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img)\n",
    "        elif isinstance(img, torch.Tensor):\n",
    "            img = img.detach().cpu().numpy()\n",
    "            if img.ndim == 3 and img.shape[0] in [1, 3]: \n",
    "                img = np.transpose(img, (1, 2, 0)) * 255.0\n",
    "            elif img.ndim == 4: \n",
    "                img = np.transpose(img[0], (1, 2, 0)) * 255.0\n",
    "        if not isinstance(img, np.ndarray): img = np.array(img)\n",
    "        return img.astype(np.float32)\n",
    "\n",
    "    def _to_tensor(self, img_np):\n",
    "        tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
    "        return tensor / 127.5 - 1.0\n",
    "\n",
    "    def evaluate(self, orig, wm):\n",
    "        img_orig_np = self._to_numpy(orig)\n",
    "        img_wm_np = self._to_numpy(wm)\n",
    "        \n",
    "        psnr = peak_signal_noise_ratio(img_orig_np, img_wm_np, data_range=255)\n",
    "        \n",
    "        try:\n",
    "            ssim = structural_similarity(img_orig_np, img_wm_np, data_range=255, channel_axis=2)\n",
    "        except TypeError:\n",
    "            ssim = structural_similarity(img_orig_np, img_wm_np, data_range=255, multichannel=True)\n",
    "            \n",
    "        lpips_val = 0.0\n",
    "        if self.lpips_model is not None:\n",
    "            t_orig = self._to_tensor(img_orig_np)\n",
    "            t_wm = self._to_tensor(img_wm_np)\n",
    "            with torch.no_grad():\n",
    "                lpips_val = self.lpips_model(t_orig, t_wm).item()\n",
    "\n",
    "        return {'psnr': psnr, 'ssim': ssim, 'lpips': lpips_val}\n",
    "\n",
    "def calculate_accuracy(predicted, target):\n",
    "    return ((predicted > 0.5).float() == (target > 0.5).float()).float().mean().item()\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"ALIEN Watermark Injection Test\")\n",
    "    \n",
    "    parser.add_argument(\"--sd_model_path\", type=str, default=\"../stable-diffusion-v1-5\", help=\"Path to Stable Diffusion model\")\n",
    "    parser.add_argument(\"--wm_model_path\", type=str, default=\"./ALIEN_Models\", help=\"Path to Watermark Encoder/Decoder\")\n",
    "    \n",
    "    parser.add_argument(\"--output_dir\", type=str, default=\"./output_alien_test\", help=\"Directory to save results\")\n",
    "    parser.add_argument(\"--prompt\", type=str, default=None, help=\"Prompt for generation (overrides default list if provided)\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=1111, help=\"Random seed base\")\n",
    "    parser.add_argument(\"--secret_len\", type=int, default=48, help=\"Length of watermark secret bits\")\n",
    "    \n",
    "    parser.add_argument(\"--wm_weight\", type=float, default=1, help=\"Strength of watermark injection\")\n",
    "    parser.add_argument(\"--start_step\", type=int, default=1, help=\"Injection start step\")\n",
    "    parser.add_argument(\"--end_step\", type=int, default=50, help=\"Injection end step\")\n",
    "    \n",
    "    parser.add_argument(\"--noise_std\", type=float, default=0.1, help=\"Standard deviation for Gaussian Noise attack\")\n",
    "    parser.add_argument(\"--jpeg_quality\", type=int, default=50, help=\"Quality for JPEG Compression attack\")\n",
    "    parser.add_argument(\"--blur_sigma\", type=float, default=1.0, help=\"Sigma for Gaussian Blur attack\")\n",
    "    \n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"üöÄ Starting ALIEN Test on {device} (Strict Numpy Noise Mode)\")\n",
    "    print(f\"üìÇ Output Dir: {args.output_dir}\")\n",
    "\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    if args.prompt:\n",
    "        prompts = [args.prompt]\n",
    "    else:\n",
    "        prompts = [\n",
    "            \"A cat, soft golden lighting, cinematic bokeh, highly detailed fur, 8k, realistic, studio lighting.\"\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "        pipeline = StableDiffusionPipeline.from_pretrained(args.sd_model_path, safety_checker=None).to(device)\n",
    "        \n",
    "        try:\n",
    "            from model import LatentMarkEncoder, LatentMarkDecoder\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è 'model' module not found, assuming classes are defined in this script or environment.\")\n",
    "            pass\n",
    "\n",
    "        wm_encoder = LatentMarkEncoder(secret_size=args.secret_len, latent_channels=4).to(device)\n",
    "        wm_decoder = LatentMarkDecoder(latent_channels=4, secret_size=args.secret_len).to(device)\n",
    "        \n",
    "        enc_path = os.path.join(args.wm_model_path, \"encoder.pth\")\n",
    "        dec_path = os.path.join(args.wm_model_path, \"decoder.pth\")\n",
    "\n",
    "        if os.path.exists(enc_path):\n",
    "            wm_encoder.load_state_dict(torch.load(enc_path, map_location='cpu'))\n",
    "            wm_decoder.load_state_dict(torch.load(dec_path, map_location='cpu'))\n",
    "            print(f\"‚úÖ Loaded Pretrained Watermark Models from {args.wm_model_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: Pretrained models not found at {args.wm_model_path}. Using random weights.\")\n",
    "            \n",
    "        wm_encoder.eval()\n",
    "        wm_decoder.eval()\n",
    "        \n",
    "        alien_pipe = WatermarkInjectionPipeline(\n",
    "            vae=pipeline.vae, text_encoder=pipeline.text_encoder, tokenizer=pipeline.tokenizer, \n",
    "            unet=pipeline.unet, scheduler=pipeline.scheduler, wm_encoder=wm_encoder, wm_decoder=wm_decoder\n",
    "        ).to(device)\n",
    "        \n",
    "        evaluator = ImageQualityEvaluator(device)\n",
    "        distorter = DistortionUnit(device)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Initialization Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "\n",
    "    stats = {'psnr': [], 'ssim': [], 'lpips': [], 'acc': defaultdict(list)}\n",
    "    \n",
    "    attacks = [\n",
    "        ('clean', 'clean', {}),\n",
    "        ('noise', 'gaussian_noise', {'std': args.noise_std}), \n",
    "        ('blur', 'gaussian_blur', {'kernel_size': (5, 5), 'sigma': (args.blur_sigma, args.blur_sigma)}),\n",
    "        ('jpeg', 'jpeg_compression', {'quality': args.jpeg_quality})\n",
    "    ]\n",
    "\n",
    "    secret_input = torch.randint(0, 2, (1, args.secret_len), dtype=torch.float32, device=device)\n",
    "    \n",
    "    print(f\"\\nüì¢ Processing {len(prompts)} images...\")\n",
    "    \n",
    "    for idx, prompt in enumerate(prompts):\n",
    "        img_id = idx + 1111\n",
    "        save_dir = f\"{args.output_dir}/img_{img_id:02d}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        seed = args.seed + idx\n",
    "        generator = torch.Generator(device).manual_seed(seed)\n",
    "        \n",
    "        print(f\"[{img_id}/{len(prompts)}] Generating: {prompt[:50]}...\")\n",
    "\n",
    "        orig_res = alien_pipe(prompt, enable_watermark=False, num_inference_steps=50, generator=generator)\n",
    "        orig_img = orig_res[\"images\"][0]\n",
    "        orig_img.save(f\"{save_dir}/original.jpg\")\n",
    "        \n",
    "        generator.manual_seed(seed) \n",
    "        alien_res = alien_pipe(\n",
    "            prompt, enable_watermark=True, secret_input=secret_input,\n",
    "            wm_injection_start_step=args.start_step, \n",
    "            wm_injection_end_step=args.end_step, \n",
    "            wm_weight=args.wm_weight,\n",
    "            num_inference_steps=50, generator=generator\n",
    "        )\n",
    "        alien_img = alien_res[\"images\"][0]\n",
    "        alien_latents = alien_res[\"latents\"]\n",
    "        alien_img.save(f\"{save_dir}/alien_wm.jpg\")\n",
    "        \n",
    "        metrics = evaluator.evaluate(orig_img, alien_img)\n",
    "        for k in ['psnr', 'ssim', 'lpips']:\n",
    "            stats[k].append(metrics[k])\n",
    "        \n",
    "        for name, method, params in attacks:\n",
    "            if method == 'clean':\n",
    "                z = alien_latents\n",
    "                d_img = alien_img \n",
    "            else:\n",
    "                d_img = distorter.apply_distortion(alien_img, method, **params)\n",
    "                d_img.save(f\"{save_dir}/attack_{name}.jpg\")\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    img_t = transforms.ToTensor()(d_img).unsqueeze(0).to(device)\n",
    "                    img_norm = img_t * 2.0 - 1.0\n",
    "                    z = pipeline.vae.encode(img_norm).latent_dist.sample() * pipeline.vae.config.scaling_factor\n",
    "            \n",
    "            decoded_secret = wm_decoder(z)\n",
    "            acc = calculate_accuracy(decoded_secret, secret_input)\n",
    "            stats['acc'][name].append(acc)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üìä ALIEN WATERMARK REPORT (N={len(prompts)})\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Visual Quality:\")\n",
    "    print(f\"  PSNR  : {np.mean(stats['psnr']):.2f}\")\n",
    "    print(f\"  SSIM  : {np.mean(stats['ssim']):.4f}\")\n",
    "    print(f\"  LPIPS : {np.mean(stats['lpips']):.4f}\")\n",
    "    \n",
    "    print(\"\\nRobustness (Bit Accuracy):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Attack':<15} | {'Accuracy':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for name, _, _ in attacks:\n",
    "        avg_acc = np.mean(stats['acc'][name])\n",
    "        print(f\"{name.upper():<15} | {avg_acc:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"‚úÖ Results saved to: {args.output_dir}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wm_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
